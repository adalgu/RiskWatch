"""
Main application module for the dashboard.
Integrates all components and provides the main entry point.
"""

import os
import streamlit as st
from datetime import datetime
import sqlalchemy as sa
from sqlalchemy.orm import sessionmaker
from sqlalchemy.orm import declarative_base
from sqlalchemy import text
import time

import pika
import json

from logging_config import get_logger
from decorators import handle_exceptions

logger = get_logger('app')

# Configuration from environment variables
DATABASE_URL = os.getenv('DATABASE_URL', 'postgresql://postgres:password@localhost:5432/news_db')
RABBITMQ_URL = os.getenv('RABBITMQ_URL', 'amqp://guest:guest@localhost:5672/')
LOG_FILE_PATH = os.getenv('COLLECTOR_LOG_PATH', '/app/logs/collector.log')

# Database setup
engine = sa.create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

class Database:
    def __init__(self):
        self.session = SessionLocal()

    def __del__(self):
        self.session.close()

    def get_date_range(self):
        """Get the date range of collected articles"""
        query = """
            SELECT MIN(published_date), MAX(published_date)
            FROM articles
        """
        result = self.session.execute(text(query)).fetchone()
        return result[0], result[1]

    def get_keywords_summary(self):
        """Get summary of collected articles by keyword"""
        query = """
            SELECT main_keyword, COUNT(*) as article_count,
                   MIN(published_date) as earliest_date,
                   MAX(published_date) as latest_date
            FROM articles
            GROUP BY main_keyword
            ORDER BY article_count DESC
        """
        return self.session.execute(text(query)).fetchall()

    def get_articles_by_date(self, start_date, end_date, keyword=None):
        """Get articles within date range and optionally filtered by keyword"""
        query = """
            SELECT DATE(published_date) as date, COUNT(*) as count
            FROM articles
            WHERE published_date BETWEEN :start_date AND :end_date
        """
        if keyword:
            query += " AND main_keyword = :keyword"
        query += " GROUP BY DATE(published_date) ORDER BY date"
        
        params = {"start_date": start_date, "end_date": end_date}
        if keyword:
            params["keyword"] = keyword
            
        return self.session.execute(text(query), params).fetchall()

    def get_articles_details_by_date(self, date, keyword=None):
        """Get detailed article information for a specific date"""
        query = """
            SELECT title, publisher, naver_link, published_at
            FROM articles
            WHERE DATE(published_date) = :date
        """
        if keyword:
            query += " AND main_keyword = :keyword"
        query += " ORDER BY published_at DESC"
        
        params = {"date": date}
        if keyword:
            params["keyword"] = keyword
            
        return self.session.execute(text(query), params).fetchall()

    def get_all_keywords(self):
        """Get list of all keywords"""
        query = """
            SELECT DISTINCT main_keyword
            FROM articles
            ORDER BY main_keyword
        """
        result = self.session.execute(text(query))
        return [row[0] for row in result]

def get_recent_logs(start_time=None):
    """Get recent collection logs"""
    try:
        if os.path.exists(LOG_FILE_PATH):
            with open(LOG_FILE_PATH, 'r', encoding='utf-8') as f:
                logs = f.readlines()
                
            # Filter logs by start time if provided
            if start_time:
                filtered_logs = []
                for log in logs:
                    try:
                        log_time_str = log.split(' - ')[0]
                        log_time = datetime.strptime(log_time_str, '%Y-%m-%d %H:%M:%S,%f')
                        if log_time >= start_time:
                            filtered_logs.append(log)
                    except (ValueError, IndexError):
                        continue
                return filtered_logs
            
            # Return last 100 lines if no start time
            return logs[-100:]
    except Exception as e:
        logger.error(f"Error reading log file: {e}")
        return []

def publish_collection_request(keyword, start_date, end_date, method, min_delay, max_delay, batch_size):
    """Publish collection request to RabbitMQ"""
    try:
        # RabbitMQ connection
        parameters = pika.URLParameters(RABBITMQ_URL)
        connection = pika.BlockingConnection(parameters)
        channel = connection.channel()

        # Declare queue
        channel.queue_declare(queue='collection_requests', durable=True)

        # Prepare message
        message = {
            'keyword': keyword,
            'start_date': start_date.isoformat(),
            'end_date': end_date.isoformat(),
            'method': method,
            'min_delay': min_delay,
            'max_delay': max_delay,
            'batch_size': batch_size,
            'request_time': datetime.now().isoformat()
        }

        # Publish message
        channel.basic_publish(
            exchange='',
            routing_key='collection_requests',
            body=json.dumps(message),
            properties=pika.BasicProperties(
                delivery_mode=2,  # make message persistent
            )
        )

        connection.close()
        return True, datetime.now()
    except Exception as e:
        logger.error(f"Failed to publish collection request: {str(e)}")
        return False, None

@handle_exceptions("ëŒ€ì‹œë³´ë“œ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")
def setup_page():
    """Initialize Streamlit page configuration"""
    st.set_page_config(
        page_title="ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ì§‘ í˜„í™©",
        page_icon="ğŸ“°",
        layout="wide",
        initial_sidebar_state="collapsed"
    )
    st.title("ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ì§‘ í˜„í™© ëŒ€ì‹œë³´ë“œ")

def render_collection_form():
    """Render the collection request form"""
    st.header("ë°ì´í„° ìˆ˜ì§‘ ìš”ì²­")
    
    with st.form("collection_form"):
        keyword = st.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œ", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì")
        
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input("ì‹œì‘ì¼")
        with col2:
            end_date = st.date_input("ì¢…ë£Œì¼")
            
        # Add new parameters
        method = st.selectbox("ìˆ˜ì§‘ ë°©ë²•", options=["SEARCH", "API"], help="SEARCH: ë„¤ì´ë²„ ê²€ìƒ‰, API: ë„¤ì´ë²„ ë‰´ìŠ¤ API")
        
        col3, col4 = st.columns(2)
        with col3:
            min_delay = st.number_input("ìµœì†Œ ë”œë ˆì´ (ì´ˆ)", min_value=1, max_value=10, value=1, help="ìš”ì²­ ì‚¬ì´ì˜ ìµœì†Œ ëŒ€ê¸° ì‹œê°„")
        with col4:
            max_delay = st.number_input("ìµœëŒ€ ë”œë ˆì´ (ì´ˆ)", min_value=1, max_value=10, value=3, help="ìš”ì²­ ì‚¬ì´ì˜ ìµœëŒ€ ëŒ€ê¸° ì‹œê°„")
            
        batch_size = st.number_input("ë°°ì¹˜ í¬ê¸°", min_value=10, max_value=10000, value=100, help="í•œ ë²ˆì— ìˆ˜ì§‘í•  ê¸°ì‚¬ ìˆ˜")
            
        submitted = st.form_submit_button("ìˆ˜ì§‘ ì‹œì‘")
        
        if submitted:
            if keyword and start_date and end_date and min_delay <= max_delay:
                success, request_time = publish_collection_request(
                    keyword=keyword,
                    start_date=start_date,
                    end_date=end_date,
                    method=method,
                    min_delay=min_delay,
                    max_delay=max_delay,
                    batch_size=batch_size
                )
                if success:
                    st.success("ìˆ˜ì§‘ ìš”ì²­ì´ ì„±ê³µì ìœ¼ë¡œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    # Store request time in session state
                    st.session_state['last_request_time'] = request_time
                    # Set auto-refresh
                    st.session_state['auto_refresh'] = True
                else:
                    st.error("ìˆ˜ì§‘ ìš”ì²­ ì „ì†¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            else:
                if min_delay > max_delay:
                    st.warning("ìµœì†Œ ë”œë ˆì´ëŠ” ìµœëŒ€ ë”œë ˆì´ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    st.warning("ëª¨ë“  í•„ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

def render_collection_status():
    """Render collection status information"""
    st.header("ìˆ˜ì§‘ í˜„í™©")
    
    db = Database()
    
    # Get all keywords and add an "ì „ì²´" option
    keywords = ["ì „ì²´"] + db.get_all_keywords()
    selected_keyword = st.selectbox("ê²€ìƒ‰ í‚¤ì›Œë“œ ì„ íƒ", keywords)
    
    # Get date range from database
    date_range = db.get_date_range()
    if date_range[0] and date_range[1]:
        # Get articles by date
        articles_by_date = db.get_articles_by_date(
            start_date=date_range[0],
            end_date=date_range[1],
            keyword=None if selected_keyword == "ì „ì²´" else selected_keyword
        )
        
        if articles_by_date:
            # Create a table with the data
            st.write("ë‚ ì§œë³„ ìˆ˜ì§‘ í˜„í™©")
            
            # Convert to a format suitable for display
            data = {
                "ë‚ ì§œ": [row.date.strftime("%Y-%m-%d") for row in articles_by_date],
                "ê¸°ì‚¬ ê°œìˆ˜": [row.count for row in articles_by_date]
            }
            
            # Display as a table
            st.dataframe(
                data,
                column_config={
                    "ë‚ ì§œ": st.column_config.TextColumn("ë‚ ì§œ", width=200),
                    "ê¸°ì‚¬ ê°œìˆ˜": st.column_config.NumberColumn("ê¸°ì‚¬ ê°œìˆ˜", width=200)
                },
                hide_index=True
            )
            
            # Show total
            total_articles = sum(row.count for row in articles_by_date)
            st.write(f"ì´ ê¸°ì‚¬ ìˆ˜: {total_articles:,}ê±´")
        else:
            st.info("ì„ íƒí•œ í‚¤ì›Œë“œì— ëŒ€í•œ ìˆ˜ì§‘ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

def render_collection_logs():
    """Render real-time collection logs"""
    st.header("ìˆ˜ì§‘ ë¡œê·¸")
    
    # Add auto-refresh toggle
    auto_refresh = st.checkbox("ìë™ ìƒˆë¡œê³ ì¹¨", 
                             value=st.session_state.get('auto_refresh', False),
                             help="5ì´ˆë§ˆë‹¤ ë¡œê·¸ë¥¼ ìë™ìœ¼ë¡œ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤")
    st.session_state['auto_refresh'] = auto_refresh
    
    # Get logs since last request
    if 'last_request_time' in st.session_state:
        logs = get_recent_logs(st.session_state['last_request_time'])
        if logs:
            log_text = ''.join(logs)
            st.text_area("ì‹¤ì‹œê°„ ìˆ˜ì§‘ ë¡œê·¸", log_text, height=400)
        else:
            st.info("ì•„ì§ ìˆ˜ì§‘ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ìˆ˜ì§‘ ìš”ì²­ì„ ì‹œì‘í•˜ë©´ ë¡œê·¸ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
    
    # Auto-refresh if enabled
    if auto_refresh:
        time.sleep(5)
        st.rerun()

@handle_exceptions("ëŒ€ì‹œë³´ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")
def main():
    """Main application entry point"""
    try:
        # Initialize page
        setup_page()
        
        # Render main sections
        render_collection_form()
        st.markdown("---")
        render_collection_status()
        st.markdown("---")
        render_collection_logs()

    except Exception as e:
        logger.error(f"Critical dashboard error: {str(e)}")
        st.error("ëŒ€ì‹œë³´ë“œ ë¡œë”© ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()
