import streamlit as st
import pandas as pd
import altair as alt
from datetime import datetime, timedelta
import sys
import os
import logging
from typing import List, Dict, Any, Optional

# ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from modules.database import Database
from modules.models import Article, Comment, CommentStats

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def setup_page():
    """í˜ì´ì§€ ì„¤ì •"""
    st.set_page_config(
        page_title="DB ê²°ê³¼ í™•ì¸",
        page_icon="ğŸ“Š",
        layout="wide"
    )
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.title("DB ê²°ê³¼ í™•ì¸")
    st.sidebar.info(
        "ì´ í˜ì´ì§€ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœ ê¸°ì‚¬ì™€ ëŒ“ê¸€ ë°ì´í„°ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )

def get_db_connection():
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´ ë°˜í™˜"""
    try:
        db = Database()
        return db
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return None

def get_article_summary(db: Database):
    """ê¸°ì‚¬ ë°ì´í„° ìš”ì•½ ì •ë³´"""
    try:
        # ì „ì²´ ê¸°ì‚¬ ìˆ˜
        query = "SELECT COUNT(*) FROM articles"
        total_articles = db.session.execute(query).scalar()
        
        # ë„¤ì´ë²„ ê¸°ì‚¬ ìˆ˜
        query = "SELECT COUNT(*) FROM articles WHERE is_naver_news = TRUE"
        naver_articles = db.session.execute(query).scalar()
        
        # í‚¤ì›Œë“œë³„ ê¸°ì‚¬ ìˆ˜
        query = """
            SELECT main_keyword, COUNT(*) as count
            FROM articles
            GROUP BY main_keyword
            ORDER BY count DESC
            LIMIT 10
        """
        keyword_counts = db.session.execute(query).fetchall()
        
        # ìµœê·¼ ìˆ˜ì§‘ ë‚ ì§œ
        query = """
            SELECT MAX(collected_at)
            FROM articles
        """
        last_collected = db.session.execute(query).scalar()
        
        return {
            "total_articles": total_articles,
            "naver_articles": naver_articles,
            "keyword_counts": keyword_counts,
            "last_collected": last_collected
        }
    except Exception as e:
        logger.error(f"ê¸°ì‚¬ ìš”ì•½ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return None

def get_comment_summary(db: Database):
    """ëŒ“ê¸€ ë°ì´í„° ìš”ì•½ ì •ë³´"""
    try:
        # ì „ì²´ ëŒ“ê¸€ ìˆ˜
        query = "SELECT COUNT(*) FROM comments"
        total_comments = db.session.execute(query).scalar()
        
        # ëŒ“ê¸€ì´ ìˆëŠ” ê¸°ì‚¬ ìˆ˜
        query = """
            SELECT COUNT(DISTINCT article_id)
            FROM comments
        """
        articles_with_comments = db.session.execute(query).scalar()
        
        # ê¸°ì‚¬ë‹¹ í‰ê·  ëŒ“ê¸€ ìˆ˜
        query = """
            SELECT AVG(comment_count)
            FROM (
                SELECT article_id, COUNT(*) as comment_count
                FROM comments
                GROUP BY article_id
            ) as subquery
        """
        avg_comments_per_article = db.session.execute(query).scalar()
        
        # ìµœê·¼ ìˆ˜ì§‘ ë‚ ì§œ
        query = """
            SELECT MAX(collected_at)
            FROM comments
        """
        last_collected = db.session.execute(query).scalar()
        
        return {
            "total_comments": total_comments,
            "articles_with_comments": articles_with_comments,
            "avg_comments_per_article": avg_comments_per_article,
            "last_collected": last_collected
        }
    except Exception as e:
        logger.error(f"ëŒ“ê¸€ ìš”ì•½ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return None

def get_top_articles_by_comments(db: Database, limit: int = 10):
    """ëŒ“ê¸€ì´ ë§ì€ ìƒìœ„ ê¸°ì‚¬ ëª©ë¡"""
    try:
        query = """
            SELECT a.id, a.title, a.publisher, a.naver_link, a.published_date, 
                   COUNT(c.id) as comment_count
            FROM articles a
            JOIN comments c ON a.id = c.article_id
            GROUP BY a.id, a.title, a.publisher, a.naver_link, a.published_date
            ORDER BY comment_count DESC
            LIMIT :limit
        """
        result = db.session.execute(query, {"limit": limit}).fetchall()
        
        # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(result, columns=[
            'ê¸°ì‚¬ID', 'ì œëª©', 'ì–¸ë¡ ì‚¬', 'ë„¤ì´ë²„ë§í¬', 'ë°œí–‰ì¼', 'ëŒ“ê¸€ìˆ˜'
        ])
        
        return df
    except Exception as e:
        logger.error(f"ëŒ“ê¸€ ë§ì€ ê¸°ì‚¬ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return pd.DataFrame()

def get_recent_articles(db: Database, days: int = 7, limit: int = 20):
    """ìµœê·¼ ìˆ˜ì§‘ëœ ê¸°ì‚¬ ëª©ë¡"""
    try:
        # ìµœê·¼ Nì¼ ê¸°ì¤€ ë‚ ì§œ ê³„ì‚°
        cutoff_date = datetime.now() - timedelta(days=days)
        
        query = """
            SELECT a.id, a.title, a.publisher, a.naver_link, a.published_date, 
                   a.main_keyword, a.collected_at
            FROM articles a
            WHERE a.collected_at > :cutoff_date
            ORDER BY a.collected_at DESC
            LIMIT :limit
        """
        result = db.session.execute(query, {
            "cutoff_date": cutoff_date,
            "limit": limit
        }).fetchall()
        
        # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(result, columns=[
            'ê¸°ì‚¬ID', 'ì œëª©', 'ì–¸ë¡ ì‚¬', 'ë„¤ì´ë²„ë§í¬', 'ë°œí–‰ì¼', 'í‚¤ì›Œë“œ', 'ìˆ˜ì§‘ì¼ì‹œ'
        ])
        
        return df
    except Exception as e:
        logger.error(f"ìµœê·¼ ê¸°ì‚¬ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return pd.DataFrame()

def get_sentiment_data(db: Database):
    """ê°ì • ë¶„ì„ ë°ì´í„° (ì‹¤ì œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê°€ìƒ ë°ì´í„°)"""
    try:
        # ê°ì • ë¶„ì„ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        query = """
            SELECT COUNT(*)
            FROM comment_stats
            WHERE sentiment_distribution IS NOT NULL
        """
        has_sentiment = db.session.execute(query).scalar() > 0
        
        if has_sentiment:
            # ì‹¤ì œ ê°ì • ë¶„ì„ ë°ì´í„° ì‚¬ìš©
            query = """
                SELECT 
                    SUM((sentiment_distribution->>'positive')::float) as positive,
                    SUM((sentiment_distribution->>'neutral')::float) as neutral,
                    SUM((sentiment_distribution->>'negative')::float) as negative
                FROM comment_stats
                WHERE sentiment_distribution IS NOT NULL
            """
            result = db.session.execute(query).fetchone()
            
            if result and result[0] is not None:
                total = sum(filter(None, result))
                if total > 0:
                    sentiment_data = pd.DataFrame({
                        'ê°ì •': ['ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •'],
                        'ë¹„ìœ¨': [
                            round(result[0] / total * 100 if result[0] else 0, 1),
                            round(result[1] / total * 100 if result[1] else 0, 1),
                            round(result[2] / total * 100 if result[2] else 0, 1)
                        ]
                    })
                    return sentiment_data, True
        
        # ê°€ìƒ ë°ì´í„° ìƒì„±
        sentiment_data = pd.DataFrame({
            'ê°ì •': ['ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •'],
            'ë¹„ìœ¨': [35, 20, 45]
        })
        return sentiment_data, False
    except Exception as e:
        logger.error(f"ê°ì • ë¶„ì„ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        # ì˜¤ë¥˜ ì‹œ ê°€ìƒ ë°ì´í„° ë°˜í™˜
        sentiment_data = pd.DataFrame({
            'ê°ì •': ['ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •'],
            'ë¹„ìœ¨': [35, 20, 45]
        })
        return sentiment_data, False

def get_daily_article_trend(db: Database, days: int = 30):
    """ì¼ë³„ ê¸°ì‚¬ ìˆ˜ì§‘ ì¶”ì´"""
    try:
        # ìµœê·¼ Nì¼ ê¸°ì¤€ ë‚ ì§œ ê³„ì‚°
        cutoff_date = datetime.now() - timedelta(days=days)
        
        query = """
            SELECT DATE(collected_at) as date, COUNT(*) as count
            FROM articles
            WHERE collected_at > :cutoff_date
            GROUP BY DATE(collected_at)
            ORDER BY date
        """
        result = db.session.execute(query, {"cutoff_date": cutoff_date}).fetchall()
        
        # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(result, columns=['ë‚ ì§œ', 'ê¸°ì‚¬ìˆ˜'])
        
        return df
    except Exception as e:
        logger.error(f"ì¼ë³„ ê¸°ì‚¬ ì¶”ì´ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return pd.DataFrame()

def get_daily_comment_trend(db: Database, days: int = 30):
    """ì¼ë³„ ëŒ“ê¸€ ìˆ˜ì§‘ ì¶”ì´"""
    try:
        # ìµœê·¼ Nì¼ ê¸°ì¤€ ë‚ ì§œ ê³„ì‚°
        cutoff_date = datetime.now() - timedelta(days=days)
        
        query = """
            SELECT DATE(collected_at) as date, COUNT(*) as count
            FROM comments
            WHERE collected_at > :cutoff_date
            GROUP BY DATE(collected_at)
            ORDER BY date
        """
        result = db.session.execute(query, {"cutoff_date": cutoff_date}).fetchall()
        
        # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(result, columns=['ë‚ ì§œ', 'ëŒ“ê¸€ìˆ˜'])
        
        return df
    except Exception as e:
        logger.error(f"ì¼ë³„ ëŒ“ê¸€ ì¶”ì´ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return pd.DataFrame()

def render_dashboard(db: Database):
    """ëŒ€ì‹œë³´ë“œ ë Œë”ë§"""
    st.title("ë°ì´í„°ë² ì´ìŠ¤ ê²°ê³¼ í™•ì¸")
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒíƒœ í™•ì¸
    if db is None:
        st.error("ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    # ìš”ì•½ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    article_summary = get_article_summary(db)
    comment_summary = get_comment_summary(db)
    
    if not article_summary or not comment_summary:
        st.error("ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìš”ì•½ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        return
    
    # ìš”ì•½ ì •ë³´ í‘œì‹œ
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ê¸°ì‚¬ ë°ì´í„° ìš”ì•½")
        st.metric("ì „ì²´ ê¸°ì‚¬ ìˆ˜", f"{article_summary['total_articles']:,}ê°œ")
        st.metric("ë„¤ì´ë²„ ê¸°ì‚¬ ìˆ˜", f"{article_summary['naver_articles']:,}ê°œ")
        st.write(f"ìµœê·¼ ìˆ˜ì§‘: {article_summary['last_collected']}")
        
        # í‚¤ì›Œë“œë³„ ê¸°ì‚¬ ìˆ˜
        st.subheader("í‚¤ì›Œë“œë³„ ê¸°ì‚¬ ìˆ˜")
        keyword_df = pd.DataFrame(article_summary['keyword_counts'], columns=['í‚¤ì›Œë“œ', 'ê¸°ì‚¬ìˆ˜'])
        
        # ì°¨íŠ¸ ìƒì„±
        keyword_chart = alt.Chart(keyword_df).mark_bar().encode(
            y=alt.Y('í‚¤ì›Œë“œ:N', sort='-x', title='í‚¤ì›Œë“œ'),
            x=alt.X('ê¸°ì‚¬ìˆ˜:Q', title='ê¸°ì‚¬ ìˆ˜'),
            tooltip=['í‚¤ì›Œë“œ', 'ê¸°ì‚¬ìˆ˜']
        ).properties(
            height=300
        )
        
        st.altair_chart(keyword_chart, use_container_width=True)
    
    with col2:
        st.subheader("ëŒ“ê¸€ ë°ì´í„° ìš”ì•½")
        st.metric("ì „ì²´ ëŒ“ê¸€ ìˆ˜", f"{comment_summary['total_comments']:,}ê°œ")
        st.metric("ëŒ“ê¸€ ìˆëŠ” ê¸°ì‚¬ ìˆ˜", f"{comment_summary['articles_with_comments']:,}ê°œ")
        if comment_summary['avg_comments_per_article']:
            st.metric("ê¸°ì‚¬ë‹¹ í‰ê·  ëŒ“ê¸€ ìˆ˜", f"{comment_summary['avg_comments_per_article']:.1f}ê°œ")
        st.write(f"ìµœê·¼ ìˆ˜ì§‘: {comment_summary['last_collected']}")
        
        # ê°ì • ë¶„ì„ íŒŒì´ ì°¨íŠ¸
        st.subheader("ëŒ“ê¸€ ê°ì • ë¶„ì„")
        sentiment_data, is_real_data = get_sentiment_data(db)
        
        if not is_real_data:
            st.caption("â€» ì‹¤ì œ ê°ì • ë¶„ì„ ë°ì´í„°ê°€ ì—†ì–´ ê°€ìƒ ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
        
        pie_chart = alt.Chart(sentiment_data).mark_arc().encode(
            theta='ë¹„ìœ¨:Q',
            color=alt.Color('ê°ì •:N', scale=alt.Scale(
                domain=['ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •'],
                range=['#2ecc71', '#95a5a6', '#e74c3c']
            )),
            tooltip=['ê°ì •', 'ë¹„ìœ¨']
        ).properties(
            height=300
        )
        
        st.altair_chart(pie_chart, use_container_width=True)
    
    # ì¼ë³„ ì¶”ì´ ì°¨íŠ¸
    st.subheader("ì¼ë³„ ë°ì´í„° ìˆ˜ì§‘ ì¶”ì´")
    
    # ê¸°ê°„ ì„ íƒ
    days = st.slider("í‘œì‹œí•  ê¸°ê°„ (ì¼)", min_value=7, max_value=90, value=30, step=1)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ì¼ë³„ ê¸°ì‚¬ ìˆ˜ì§‘ ì¶”ì´")
        article_trend = get_daily_article_trend(db, days)
        
        if not article_trend.empty:
            article_chart = alt.Chart(article_trend).mark_line(point=True).encode(
                x=alt.X('ë‚ ì§œ:T', title='ë‚ ì§œ'),
                y=alt.Y('ê¸°ì‚¬ìˆ˜:Q', title='ê¸°ì‚¬ ìˆ˜'),
                tooltip=['ë‚ ì§œ', 'ê¸°ì‚¬ìˆ˜']
            ).properties(
                height=300
            )
            
            st.altair_chart(article_chart, use_container_width=True)
        else:
            st.info("í‘œì‹œí•  ê¸°ì‚¬ ì¶”ì´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with col2:
        st.subheader("ì¼ë³„ ëŒ“ê¸€ ìˆ˜ì§‘ ì¶”ì´")
        comment_trend = get_daily_comment_trend(db, days)
        
        if not comment_trend.empty:
            comment_chart = alt.Chart(comment_trend).mark_line(point=True).encode(
                x=alt.X('ë‚ ì§œ:T', title='ë‚ ì§œ'),
                y=alt.Y('ëŒ“ê¸€ìˆ˜:Q', title='ëŒ“ê¸€ ìˆ˜'),
                tooltip=['ë‚ ì§œ', 'ëŒ“ê¸€ìˆ˜']
            ).properties(
                height=300
            )
            
            st.altair_chart(comment_chart, use_container_width=True)
        else:
            st.info("í‘œì‹œí•  ëŒ“ê¸€ ì¶”ì´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ëŒ“ê¸€ì´ ë§ì€ ìƒìœ„ ê¸°ì‚¬
    st.subheader("ëŒ“ê¸€ì´ ë§ì€ ìƒìœ„ ê¸°ì‚¬")
    top_articles = get_top_articles_by_comments(db)
    
    if not top_articles.empty:
        # ë„¤ì´ë²„ ë§í¬ë¥¼ í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ë¡œ ë³€í™˜
        top_articles['ë„¤ì´ë²„ë§í¬'] = top_articles['ë„¤ì´ë²„ë§í¬'].apply(
            lambda x: f'{x}' if pd.notnull(x) else ''
        )
        
        st.dataframe(
            top_articles,
            use_container_width=True,
            column_config={
                "ê¸°ì‚¬ID": None,  # ìˆ¨ê¹€
                "ë„¤ì´ë²„ë§í¬": st.column_config.LinkColumn(),
                "ë°œí–‰ì¼": st.column_config.DatetimeColumn(
                    "ë°œí–‰ì¼",
                    format="YYYY-MM-DD HH:mm"
                ),
                "ëŒ“ê¸€ìˆ˜": st.column_config.NumberColumn(
                    "ëŒ“ê¸€ìˆ˜",
                    help="ê¸°ì‚¬ì— ë‹¬ë¦° ì´ ëŒ“ê¸€ ìˆ˜",
                    format="%dê°œ"
                )
            }
        )
    else:
        st.info("ëŒ“ê¸€ì´ ìˆëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ìµœê·¼ ìˆ˜ì§‘ëœ ê¸°ì‚¬
    st.subheader("ìµœê·¼ ìˆ˜ì§‘ëœ ê¸°ì‚¬")
    recent_days = st.slider("ìµœê·¼ ê¸°ê°„ ì„ íƒ (ì¼)", min_value=1, max_value=30, value=7, step=1)
    recent_articles = get_recent_articles(db, days=recent_days)
    
    if not recent_articles.empty:
        # ë„¤ì´ë²„ ë§í¬ë¥¼ í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ë¡œ ë³€í™˜
        recent_articles['ë„¤ì´ë²„ë§í¬'] = recent_articles['ë„¤ì´ë²„ë§í¬'].apply(
            lambda x: f'{x}' if pd.notnull(x) else ''
        )
        
        st.dataframe(
            recent_articles,
            use_container_width=True,
            column_config={
                "ê¸°ì‚¬ID": None,  # ìˆ¨ê¹€
                "ë„¤ì´ë²„ë§í¬": st.column_config.LinkColumn(),
                "ë°œí–‰ì¼": st.column_config.DatetimeColumn(
                    "ë°œí–‰ì¼",
                    format="YYYY-MM-DD HH:mm"
                ),
                "ìˆ˜ì§‘ì¼ì‹œ": st.column_config.DatetimeColumn(
                    "ìˆ˜ì§‘ì¼ì‹œ",
                    format="YYYY-MM-DD HH:mm:ss"
                )
            }
        )
    else:
        st.info(f"ìµœê·¼ {recent_days}ì¼ ë™ì•ˆ ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

def main():
    setup_page()
    db = get_db_connection()
    render_dashboard(db)

if __name__ == "__main__":
    main()
